(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[824],{1469:(e,t,l)=>{"use strict";Object.defineProperty(t,"__esModule",{value:!0}),!function(e,t){for(var l in t)Object.defineProperty(e,l,{enumerable:!0,get:t[l]})}(t,{default:function(){return d},getImageProps:function(){return r}});let s=l(8229),i=l(8883),n=l(3063),a=s._(l(1193));function r(e){let{props:t}=(0,i.getImgProps)(e,{defaultLoader:a.default,imgConf:{deviceSizes:[640,750,828,1080,1200,1920,2048,3840],imageSizes:[16,32,48,64,96,128,256,384],path:"/_next/image",loader:"default",dangerouslyAllowSVG:!1,unoptimized:!0}});for(let[e,l]of Object.entries(t))void 0===l&&delete t[e];return{props:t}}let d=n.Image},5091:(e,t,l)=>{"use strict";l.r(t),l.d(t,{default:()=>n});var s=l(5155);l(2115);var i=l(6766);function n(){return(0,s.jsx)("div",{className:"min-h-screen flex flex-col items-center bg-black/90 px-4 pt-32 pb-16",children:(0,s.jsxs)("div",{className:"w-full max-w-3xl bg-black/60 rounded-2xl p-10 shadow-2xl border border-white/10 text-gray-200 animate-fade-in-up",children:[(0,s.jsx)("h1",{className:"text-3xl md:text-4xl font-extrabold text-blue-400 mb-4 tracking-tight",children:"Reward Modeling in LLMs"}),(0,s.jsx)("div",{className:"text-gray-400 mb-6 text-sm",children:"March 2025"}),(0,s.jsx)("div",{className:"w-full flex justify-center mb-8",children:(0,s.jsx)(i.default,{src:"/iitb.png",alt:"Reward Modeling in LLMs",width:400,height:220,className:"rounded-xl shadow-lg"})}),(0,s.jsx)("p",{className:"mb-4",children:"A practical guide to reward modeling and its role in post-training of LLMs."}),(0,s.jsx)("h2",{className:"text-2xl font-bold text-yellow-300 mb-2 mt-8",children:"What is Reward Modeling?"}),(0,s.jsx)("p",{className:"mb-4",children:"Reward modeling is the process of training a model to predict human preferences, which is then used to guide reinforcement learning for language models."}),(0,s.jsx)("h2",{className:"text-2xl font-bold text-yellow-300 mb-2 mt-8",children:"Why is it Important?"}),(0,s.jsxs)("ul",{className:"list-disc list-inside mb-4",children:[(0,s.jsx)("li",{children:"Aligns LLMs with human values"}),(0,s.jsx)("li",{children:"Improves safety and usefulness"}),(0,s.jsx)("li",{children:"Enables fine-tuning for specific tasks"})]}),(0,s.jsx)("p",{className:"mb-4",children:"Reward modeling is a foundational step in the RLHF pipeline for LLMs."})]})})}},6766:(e,t,l)=>{"use strict";l.d(t,{default:()=>i.a});var s=l(1469),i=l.n(s)},9970:(e,t,l)=>{Promise.resolve().then(l.bind(l,5091))}},e=>{var t=t=>e(e.s=t);e.O(0,[63,441,684,358],()=>t(9970)),_N_E=e.O()}]);